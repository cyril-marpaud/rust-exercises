//! # TP : R√©seau de Neurones - Conversion Celsius vers Fahrenheit
//!
//! ## Objectif
//!
//! Dans ce TP, vous allez impl√©menter un r√©seau de neurones simple capable d'apprendre la conversion de temp√©ratures Celsius vers Fahrenheit. La formule math√©matique est $F = C \times \frac{9}{5} + 32$.
//!
//! Le r√©seau de neurones va apprendre cette relation affine sans qu'on lui fournisse explicitement la formule. Il ne "comprend" pas les temp√©ratures, il ajuste juste des nombres jusqu'√† ce que ses pr√©dictions correspondent aux exemples.
//!
//! ## Introduction : Qu'est-ce qu'un neurone artificiel ?
//!
//! Un neurone artificiel est inspir√© du neurone biologique. Il re√ßoit des entr√©es, les traite, et produit une sortie.
//!
//! ```
//! Entr√©es            Neurone          Sortie
//!    ‚Üì
//!    x‚ÇÅ ‚îÄ‚îÄ‚îÄw‚ÇÅ‚îÄ‚îÄ‚îê somme w‚®âx   activation
//!              ‚îÇ     ‚Üì           ‚Üì
//!    x‚ÇÇ ‚îÄ‚îÄ‚îÄw‚ÇÇ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ[ Œ£ + b ]‚îÄ‚îÄ‚îÄ[ f ]‚îÄ‚îÄ‚îÄ> y
//!              ‚îÇ         ‚Üë
//!    x‚ÇÉ ‚îÄ‚îÄ‚îÄw‚ÇÉ‚îÄ‚îÄ‚îò       biais
//!          ‚Üë
//!        Poids
//! ```
//!
//! ### Les composants :
//!
//! - **Entr√©es (x)** : Les valeurs qu'on donne au neurone (ex: temp√©rature en Celsius)
//! - **Poids (w)** : L'importance de chaque entr√©e (comme un volume sur un canal audio)
//! - **Biais (b)** : Un ajustement constant (comme le r√©glage de luminosit√© de base d'un √©cran)
//! - **Fonction d'activation (f)** : Transformation finale (ex: ReLU = "si n√©gatif, mets 0")
//!
//! ### Calcul de la sortie du neurone :
//!
//! $$ y = f(x_1 \times w_1 + x_2 \times w_2 + x_3 \times w_3 + b) $$
//!
//! ## Architecture du r√©seau
//!
//! Pour cette t√¢che simple, nous utiliserons :
//! - 1 neurone d'entr√©e (temp√©rature en Celsius)
//! - 2 neurones cach√©s (pour apprendre la transformation)
//! - 1 neurone de sortie (temp√©rature en Fahrenheit)
//!
//! ```
//! ENTR√âE               COUCHE CACH√âE           SORTIE
//!   (1)                    (2)                  (1)
//!
//!            ‚îå‚îÄ‚îÄ‚îÄ w‚ÇÅ‚ÇÅ ‚îÄ‚îÄ‚îÄ> [N‚ÇÅ] ‚îÄ‚îÄ‚îÄ w‚ÇÇ‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îê
//!   20¬∞C ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                             ‚îú‚îÄ‚îÄ‚îÄ> 68¬∞F
//!            ‚îî‚îÄ‚îÄ‚îÄ w‚ÇÅ‚ÇÇ ‚îÄ‚îÄ‚îÄ> [N‚ÇÇ] ‚îÄ‚îÄ‚îÄ w‚ÇÇ‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îò
//! ```
//!
//! ## √âtape 1 : Structure de base du r√©seau
//!
//! ### Comprendre les poids et biais : Pourquoi des matrices ?
//!
//! #### Pour UN neurone :
//!
//! ```
//! Temp√©rature ‚îÄ‚îÄ‚îÄ‚îÄ[Neurone: w=1.8, b=32]‚îÄ‚îÄ‚îÄ‚îÄ> Contribution
//!     20¬∞C            20√ó1.8+32=68                 68¬∞F
//! ```
//!
//! #### Pour PLUSIEURS neurones (une couche) :
//!
//! ```
//!           ‚îå‚îÄ‚îÄ‚îÄ[Neurone‚ÇÅ: w=0.9, b=10]‚îÄ‚îÄ> 28¬∞
//! 20¬∞C ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         20√ó0.9+10=28
//!           ‚îî‚îÄ‚îÄ‚îÄ[Neurone‚ÇÇ: w=2.5, b=5]‚îÄ‚îÄ‚îÄ> 55¬∞
//!                     20√ó2.5+5=55
//! ```
//!
//! Chaque neurone a **son propre poids** pour chaque entr√©e !
//!
//! #### Repr√©sentation matricielle :
//!
//! Pour une couche de 2 neurones recevant 1 entr√©e :
//!
//! $$
//! W = \begin{bmatrix} w_1 \\\\ w_2 \end{bmatrix} = \begin{bmatrix} 0.9 \\\\ 2.5 \end{bmatrix}
//! \quad \text{et} \quad
//! B = \begin{bmatrix} b_1 \\\\ b_2 \end{bmatrix} = \begin{bmatrix} 10 \\\\ 5 \end{bmatrix}
//! $$
//!
//! **Pourquoi une matrice ?** Parce qu'avec plusieurs entr√©es et plusieurs neurones :
//!
//! $$
//! W = \begin{bmatrix}
//! w_{11} & w_{12} \\\\
//! w_{21} & w_{22} \\\\
//! w_{31} & w_{32}
//! \end{bmatrix}
//! \quad \text{(2 entr√©es ‚Üí 3 neurones = 6 connexions = matrice } 3 \times 2\text{)}
//! $$
//!
//! ### 1.1 D√©finir la structure `Layer`
//!
//! Impl√©mentez une structure `Layer` qui repr√©sente une couche de neurones. Pour les poids et les biais, nous utiliserons le type `f64`.
//!
//! Une layer (couche) se compose :
//! - Des poids sous forme de matrice
//! - Des biais sous forme de vecteur
//! - D'une fonction d'activation : un enum `ActivationFunction` dont nous d√©finirons les variants dans la prochaine section
//!
//! <details>
//! <summary>üí° Indice : matrices</summary>
//!
//! Une matrice peut √™tre repr√©sent√©e sous forme d'un vecteur de vecteurs.
//! </details>
//!
//! ### 1.2 D√©finir les fonctions d'activation
//!
//! Les fonctions d'activation permettent d'introduire de la non-lin√©arit√© dans le r√©seau. Il existe de nombreuses fonctions d'activation possibles (Sigmoid, Tanh, Leaky ReLU, ELU, etc.), mais nous allons utiliser les deux plus simples :
//!
//! - **Linear** : $f(x) = x$ (pour la couche de sortie car on veut une valeur non born√©e)
//! - **ReLU** : $f(x) = \max(0, x)$ (pour la couche cach√©e)
//!
//! ReLU est privil√©gi√©e pour les couches cach√©es car elle est tr√®s simple √† calculer tout en √©vitant les probl√®mes de gradient qui dispara√Æt, contrairement aux fonctions saturantes comme Sigmoid ou Tanh.
//!
//! Impl√©menter :
//! - Un enum `ActivationFunction` avec les variants `Linear` et `ReLU`
//! - La m√©thode `apply` pour appliquer la fonction d'activation sur un `f64`
//! - La m√©thode `derivative` pour calculer la d√©riv√©e (n√©cessaire pour la r√©tropropagation) :
//!   - **Linear** : $f'(x) = 1$
//!   - **ReLU** : $f'(x) = \begin{cases} 1 & \text{si } x > 0 \\\\ 0 & \text{sinon} \end{cases}$
//!
//! ### 1.3 D√©finir la structure `NeuralNetwork`
//!
//! Impl√©menter une structure `NeuralNetwork` qui repr√©sente le r√©seau de neurones complet.
//!
//! Le r√©seau est simplement compos√© d'un vecteur de layers.
//!
//! ## √âtape 2 : Initialisation du r√©seau
//!
//! ### Pourquoi initialiser al√©atoirement ?
//!
//! Si tous les poids et biais sont initialis√©s √† 0, tous les neurones d'une m√™me couche produisent la m√™me sortie et re√ßoivent les m√™mes gradients pendant l'entra√Ænement. Ils √©voluent donc de mani√®re identique et le r√©seau ne peut pas apprendre de repr√©sentations complexes. L'initialisation al√©atoire brise cette sym√©trie.
//!
//! **Attention** : Des poids trop grands peuvent causer des probl√®mes :
//! - Valeurs qui explosent
//! - Neurones morts avec ReLU (si entr√©e √ó poids + biais < 0 ‚Üí toujours 0)
//!
//! C'est pourquoi nous initialiserons les poids et biais avec de petites valeurs al√©atoires entre -0.5 et 0.5.
//!
//! ### 2.1 Constructeur de Layer
//!
//! Impl√©menter un constructeur `new` pour la structure `Layer` qui :
//! - Prend en param√®tre :
//!   - Le nombre de neurones d'entr√©e
//!   - Le nombre de neurones de sortie
//!   - La fonction d'activation √† utiliser
//! - Cr√©e et initialise al√©atoirement la matrice des poids
//! - Cr√©e et initialise al√©atoirement le vecteur des biais
//!
//! <details>
//! <summary>üí° Indice : initialisation al√©atoire</summary>
//!
//! On peut utiliser la m√©thode [`gen_range`](https://docs.rs/rand/latest/rand/trait.Rng.html#method.gen_range) du crate [`rand`](https://docs.rs/rand/).
//! </details>
//!
//! ### 2.2 Constructeur de NeuralNetwork
//!
//! Impl√©menter un constructeur `new` pour la structure `NeuralNetwork` qui :
//! - Prend en param√®tre :
//!   - Le nombre de neurones d'entr√©e
//!   - Un vecteur contenant le nombre de neurones pour chaque couche cach√©e
//!   - Le nombre de neurones de sortie
//! - Construit automatiquement toutes les couches n√©cessaires :
//!   - Les couches cach√©es utilisent la fonction d'activation ReLU
//!   - La couche de sortie utilise la fonction d'activation Linear
//! - Retourne le r√©seau initialis√©
//!
//! <details>
//! <summary>üí° Indice : Architecture pour notre probl√®me</summary>
//!
//! Pour la conversion Celsius ‚Üí Fahrenheit, nous allons cr√©er un r√©seau avec :
//! - 1 neurone d'entr√©e (la temp√©rature en Celsius)
//! - 2 neurones dans la couche cach√©e
//! - 1 neurone de sortie (la temp√©rature en Fahrenheit)
//!
//! Donc l'appel au constructeur ressemblera √† : `NeuralNetwork::new(1, vec![2], 1)`
//! </details>
//!
//! ## √âtape 3 : Normalisation des donn√©es
//!
//! ### Pourquoi normaliser ?
//!
//! Les r√©seaux de neurones fonctionnent mieux avec des valeurs entre 0 et 1 :
//! - **Probl√®mes num√©riques** : Des valeurs comme 40¬∞C peuvent, apr√®s multiplication par les poids et accumulation dans les couches, produire des nombres tr√®s grands causant des overflows
//! - **Gradients d√©s√©quilibr√©s** : Sans normalisation, les gradients pour les grandes valeurs dominent l'apprentissage
//! - **Convergence instable** : Les poids doivent compenser les diff√©rentes √©chelles, ralentissant l'apprentissage
//!
//! ### Processus de normalisation
//!
//! La normalisation transforme une plage de valeurs [min, max] vers [0, 1] :
//!
//! ```
//! Valeurs originales :  -40¬∞C ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0¬∞C ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 40¬∞C
//!                         ‚Üì               ‚Üì               ‚Üì
//! Valeurs normalis√©es :   0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1
//! ```
//!
//! Apr√®s l'entra√Ænement, il faudra d√©normaliser les pr√©dictions pour obtenir des temp√©ratures r√©elles :
//!
//! ```
//! Entr√©e ‚Üí Normalisation ‚Üí R√©seau ‚Üí Sortie normalis√©e ‚Üí D√©normalisation ‚Üí R√©sultat
//! 20¬∞C   ‚Üí     0.75      ‚Üí   NN   ‚Üí       0.85        ‚Üí      68¬∞F       ‚Üí   68¬∞F
//! ```
//!
//! ### 3.1 Structure de normalisation
//!
//! Impl√©menter une structure `Normalizer` qui :
//! - Contient deux champs `f64` : `min` et `max` d√©finissant la plage de valeurs
//! - Poss√®de un constructeur `new` prenant ces deux valeurs en param√®tres
//! - Impl√©mente deux m√©thodes associ√©es :
//!   - `normalize` : $ x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}} $
//!   - `denormalize` : $ x = x_{norm} \times (x_{max} - x_{min}) + x_{min} $
//!
//! ### 3.2 Normaliseurs pour notre probl√®me
//!
//! Nous aurons besoin de deux instances de `Normalizer` :
//! - Une pour les temp√©ratures Celsius (entr√©e) : plage [-40, 40]
//! - Une pour les temp√©ratures Fahrenheit (sortie) : plage [-40, 104]
//!
//! Durant l'entra√Ænement, il ne faudra pas oublier de :
//! 1. Normaliser la temp√©rature Celsius avant de la donner au r√©seau
//! 2. Normaliser la temp√©rature Fahrenheit cible pour calculer l'erreur
//! 3. D√©normaliser la sortie apr√®s pr√©diction pour obtenir la temp√©rature en Fahrenheit
//!
//! ## √âtape 4 : Propagation avant (Forward Pass)
//!
//! ### Comprendre le Forward Pass
//!
//! Le forward pass, c'est suivre le chemin des donn√©es de l'entr√©e vers la sortie.
//!
//! ```
//! ENTR√âE               COUCHE CACH√âE           SORTIE
//!   (1)                    (2)                  (1)
//!
//!            ‚îå‚îÄ‚îÄ‚îÄ w‚ÇÅ‚ÇÅ ‚îÄ‚îÄ‚îÄ> [N‚ÇÅ] ‚îÄ‚îÄ‚îÄ w‚ÇÇ‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îê
//!   20¬∞C ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                             ‚îú‚îÄ‚îÄ‚îÄ> 68¬∞F
//!            ‚îî‚îÄ‚îÄ‚îÄ w‚ÇÅ‚ÇÇ ‚îÄ‚îÄ‚îÄ> [N‚ÇÇ] ‚îÄ‚îÄ‚îÄ w‚ÇÇ‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îò
//!                                        
//! √âtape 1: Calcul couche cach√©e    √âtape 2: Calcul sortie
//! N‚ÇÅ = ReLU(20√ów‚ÇÅ‚ÇÅ + b‚ÇÅ)           Sortie = Linear(N‚ÇÅ√ów‚ÇÇ‚ÇÅ + N‚ÇÇ√ów‚ÇÇ‚ÇÇ + b‚ÇÉ)
//! N‚ÇÇ = ReLU(20√ów‚ÇÅ‚ÇÇ + b‚ÇÇ)
//! ```
//!
//! ### Exemple concret pas √† pas :
//!
//! 1. **Entr√©e** : 20¬∞C (normalis√© √† 0.75)
//! 2. **Vers neurone cach√© 1** : 0.75 √ó 0.3 + 0.1 = 0.325 ‚Üí ReLU ‚Üí 0.325
//! 3. **Vers neurone cach√© 2** : 0.75 √ó -0.2 + 0.4 = 0.25 ‚Üí ReLU ‚Üí 0.25  
//! 4. **Vers sortie** : 0.325 √ó 2.0 + 0.25 √ó 1.5 + 0.2 = 1.225
//! 5. **D√©normalisation** : 68¬∞F
//!
//! ### 4.1 Forward pass pour une couche (Layer)
//!
//! Nous allons commencer par impl√©menter la propagation avant pour une seule couche. Chaque couche transforme son entr√©e selon la formule math√©matique du neurone.
//!
//! Impl√©menter une m√©thode `forward` sur `Layer` qui :
//! - Prend en param√®tre une slice d'entr√©e (`&[f64]`) repr√©sentant les valeurs d'entr√©e de la couche
//! - Retourne un vecteur (`Vec<f64>`) contenant les sorties de tous les neurones de cette couche
//!
//! #### Pourquoi une slice en entr√©e ?
//!
//! M√™me si notre probl√®me n'a qu'une seule valeur d'entr√©e (temp√©rature), les couches cach√©es re√ßoivent les sorties de la couche pr√©c√©dente qui peuvent √™tre multiples (2 neurones cach√©s dans notre cas).
//!
//! #### Algorithme d√©taill√© pour chaque neurone :
//!
//! Pour une couche avec `n` neurones de sortie, cr√©er un vecteur `output` de taille `n`. Pour chaque neurone `i` :
//!
//! 1. **Calculer la somme pond√©r√©e** :
//!    - Parcourir `weights[i]` et `input` simultan√©ment
//!    - Multiplier chaque poids par son entr√©e correspondante
//!    - Faire la somme de tous ces produits
//!
//! 2. **Ajouter le biais** :
//!    - Ajouter `biases[i]` √† la somme calcul√©e
//!
//! 3. **Appliquer l'activation** :
//!    - Utiliser la m√©thode `apply` de `self.activation` sur le r√©sultat
//!
//! <details>
//! <summary>üí° Indice : It√©ration simultan√©e</summary>
//!
//! Pour parcourir deux vecteurs simultan√©ment en Rust, utiliser la m√©thode [`zip`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip) :
//!
//! ```rust
//! weights[i].iter().zip(input)
//! ```
//!
//! Pour calculer une somme de produits, cha√Æner avec les m√©thodes [`map`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map) et [`sum`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.sum).
//! </details>
//!
//! ### 4.2 Forward pass pour le r√©seau complet
//!
//! Le r√©seau doit propager l'entr√©e √† travers toutes les couches successivement.
//!
//! #### Deux besoins diff√©rents
//!
//! Notre r√©seau aura besoin de deux m√©thodes de forward pass :
//!
//! 1. **Pour l'entra√Ænement** : Garder toutes les activations interm√©diaires pour la r√©tropropagation
//! 2. **Pour l'inf√©rence** : Juste obtenir la sortie finale
//!
//! #### 4.2.1 Forward pass complet (pour l'entra√Ænement)
//!
//! Impl√©menter une m√©thode `forward` sur `NeuralNetwork` qui :
//! - Prend une slice `&[f64]` en entr√©e (m√™me si c'est un seul √©l√©ment pour notre probl√®me)
//! - Retourne `Vec<Vec<f64>>` contenant TOUTES les activations (entr√©e + sorties de chaque couche)
//!
//! **Pourquoi garder toutes les activations ?**
//!
//! Lors de la r√©tropropagation, pour calculer les gradients d'une couche, nous avons besoin :
//! - Des activations de la couche pr√©c√©dente (entr√©es de cette couche)
//! - Des activations de cette couche (pour appliquer la d√©riv√©e de l'activation)
//!
//! **Algorithme :**
//!
//! 1. Cr√©er un vecteur `activations` et y ajouter l'entr√©e
//! 2. Initialiser `current` avec l'entr√©e
//! 3. Pour chaque couche :
//!    - Calculer `current = layer.forward(&current)`
//!    - Ajouter `current` au vecteur d'`activations`
//! 4. Retourner `activations`
//!
//! <details>
//! <summary>üí° Indice : Structure des activations</summary>
//!
//! Pour un r√©seau [1, 2, 1] avec entr√©e 0.75, les activations ressembleraient √† :
//! ```
//! [
//!   [0.75],        // Entr√©e
//!   [0.3, 0.5],    // Sortie couche cach√©e (2 neurones)
//!   [0.85]         // Sortie finale
//! ]
//! ```
//! </details>
//!
//! #### 4.2.2 Forward pass simple (pour l'inf√©rence)
//!
//! Impl√©menter une m√©thode `infer` sur `NeuralNetwork` qui :
//! - Prend un `f64` en entr√©e (temp√©rature unique)
//! - Retourne un `f64` (pr√©diction)
//! - Utilise la m√©thode `forward` d√©finie pr√©c√©demment
//!
//! Cette m√©thode est une interface simplifi√©e qui :
//! 1. Convertit l'entr√©e scalaire en vecteur `[input]`
//! 2. Appelle `forward`
//! 3. Extrait le premier (et seul) √©l√©ment de la derni√®re activation
//!
//! ### 4.3 Test du forward pass
//!
//! Avant d'impl√©menter la r√©tropropagation, tester que le forward pass fonctionne :
//!
//! ```rust
//! // Dans une fonction de test ou main
//! let network = NeuralNetwork::new(1, vec![2], 1);
//! let input = 0.5; // Temp√©rature normalis√©e
//! let output = network.infer(input);
//! println!("Entr√©e: {}, Sortie: {}", input, output);
//! ```
//!
//! **R√©sultat attendu** : Une valeur al√©atoire (le r√©seau n'est pas entra√Æn√©), mais le code ne doit pas paniquer.
//!
//! ## √âtape 5 : R√©tropropagation - La m√©thode `backward`
//!
//! ### Concept g√©n√©ral
//!
//! La r√©tropropagation est l'algorithme qui permet au r√©seau d'apprendre de ses erreurs. Apr√®s avoir fait une pr√©diction, on mesure √† quel point on s'est tromp√©, puis on ajuste tous les poids du r√©seau pour faire mieux la prochaine fois.
//!
//! Imaginez que vous apprenez √† lancer des fl√©chettes :
//! 1. Vous lancez (forward pass)
//! 2. Vous voyez o√π vous avez touch√© par rapport au centre (erreur)
//! 3. Vous ajustez votre position et votre geste (backward pass)
//! 4. Vous relancez avec ces ajustements
//!
//! ### Bagage th√©orique n√©cessaire
//!
//! **MSE (Mean Squared Error)** : L'erreur quadratique moyenne est notre fa√ßon de mesurer √† quel point une pr√©diction est fausse. On calcule `(pr√©diction - cible)¬≤` puis on divise par 2 pour simplifier les calculs. Le carr√© garantit que l'erreur est toujours positive et p√©nalise plus les grosses erreurs.
//!
//! **Gradient** : Le gradient est la "pente" de l'erreur. Il nous dit dans quelle direction et de combien ajuster chaque poids. Si le gradient est positif, on diminue le poids ; s'il est n√©gatif, on l'augmente.
//!
//! **Learning rate** : C'est la taille du pas d'ajustement. Trop grand (0.5), on risque de "sauter" par-dessus la bonne solution. Trop petit (0.001), on apprend trop lentement. Une valeur de 0.1 est g√©n√©ralement un bon compromis.
//!
//! **Propagation de l'erreur entre couches** : Quand un neurone de la couche 2 a une erreur, cette erreur doit √™tre redistribu√©e aux neurones de la couche 1 qui y ont contribu√©. La contribution de chaque neurone est proportionnelle √† son poids de connexion. Si le poids est 2.0, il a contribu√© deux fois plus qu'un poids de 1.0.
//!
//! ### Description de la m√©thode `backward`
//!
//! Impl√©menter une m√©thode `backward` sur `NeuralNetwork` qui :
//! - Prend en param√®tres :
//!   - `target: f64` : la valeur qu'on aurait d√ª pr√©dire
//!   - `activations: &[Vec<f64>]` : toutes les valeurs calcul√©es pendant le forward
//!   - `learning_rate: f64` : la force des ajustements (typiquement 0.1)
//! - Modifie directement les poids et biais du r√©seau (`&mut self`)
//!
//! ### Algorithme d√©taill√©
//!
//! 1. **Calculer l'erreur de d√©part** :
//!    ```
//!    erreur = pr√©diction - target
//!    ```
//!    La pr√©diction est `activations.last().unwrap()[0]`
//!
//! 2. **Parcourir chaque couche en sens inverse** (de la sortie vers l'entr√©e) :
//!    
//!    Pour chaque couche √† l'index `layer_idx` :
//!    - R√©cup√©rer les activations d'entr√©e : `activations[layer_idx]`
//!    - R√©cup√©rer les activations de sortie : `activations[layer_idx + 1]`
//!    - Cr√©er un vecteur `next_error` de la taille de l'entr√©e, initialis√© √† 0
//!    
//!    Pour chaque neurone `i` de cette couche :
//!    
//!    a. **Calculer le "delta"** (l'ajustement n√©cessaire) :
//!       ```
//!       delta = erreur √ó layer.activation.derivative(output_activation[i])
//!       ```
//!       La m√©thode `derivative` est d√©j√† impl√©ment√©e sur `ActivationFunction`
//!    
//!    b. **Ajuster le biais** :
//!       ```
//!       biais[i] = biais[i] - (learning_rate √ó delta)
//!       ```
//!    
//!    c. **Pour chaque poids `j` du neurone `i`** :
//!       - **Propager l'erreur** : La contribution de ce poids √† l'erreur est `poids[i][j] √ó delta`.
//!         L'ajouter √† `next_error[j]` :
//!         ```
//!         next_error[j] += poids[i][j] √ó delta
//!         ```
//!       - **Ajuster le poids** :
//!         ```
//!         poids[i][j] = poids[i][j] - (learning_rate √ó delta √ó input_activation[j])
//!         ```
//!
//! 3. **Pr√©parer l'erreur pour la prochaine it√©ration** :
//!    - Pour un r√©seau multi-couches : `error = next_error[0]` (on propage seulement le premier √©l√©ment car on n'a qu'une entr√©e)
//!    - Pour la premi√®re couche (layer_idx == 0) : on peut ignorer `next_error` car il n'y a pas de couche pr√©c√©dente
//!
//! <details>
//! <summary>üí° Indice : Structure compl√®te</summary>
//!
//! ```rust
//! let mut error = activations.last().unwrap()[0] - target;
//!
//! for (layer_idx, layer) in self.layers.iter_mut().enumerate().rev() {
//!     let input_activation = &activations[layer_idx];
//!     let output_activation = &activations[layer_idx + 1];
//!     let mut next_error = vec![0.0; input_activation.len()];
//!     
//!     // Parcourir weights et biases ensemble avec zip et enumerate
//!     for (i, (weight_row, bias)) in layer.weights.iter_mut()
//!                                          .zip(&mut layer.biases)
//!                                          .enumerate() {
//!         // Calculer delta en utilisant derivative
//!         // Mettre √† jour le biais
//!         // Parcourir chaque poids dans weight_row
//!         //   - Ajouter la contribution √† next_error
//!         //   - Mettre √† jour le poids
//!     }
//!     
//!     // Pr√©parer error pour la prochaine couche
//!     error = if layer_idx == 0 { 0.0 } else { next_error[0] };
//! }
//! ```
//! </details>
//!
//! ### Exemple concret
//!
//! Pour mieux comprendre, prenons un exemple avec des valeurs :
//! - Erreur de sortie : 7.0
//! - Poids de la couche de sortie vers neurone 1 : 2.0
//! - Poids de la couche de sortie vers neurone 2 : 1.5
//!
//! L'erreur est redistribu√©e :
//! - Neurone 1 re√ßoit : 7.0 √ó 2.0 = 14.0 d'erreur
//! - Neurone 2 re√ßoit : 7.0 √ó 1.5 = 10.5 d'erreur
//!
//! Chaque neurone ajuste ensuite ses propres poids en fonction de cette erreur re√ßue.
//!
//! ## √âtape 6 : Entra√Ænement - La m√©thode `train`
//!
//! ### Concept g√©n√©ral
//!
//! L'entra√Ænement est le processus r√©p√©titif qui fait apprendre le r√©seau. Une **√©poque** est un passage complet sur tous les exemples d'entra√Ænement. On fait g√©n√©ralement des centaines ou milliers d'√©poques pour que le r√©seau apprenne bien.
//!
//! √Ä chaque √©poque :
//! 1. On pr√©sente chaque exemple au r√©seau
//! 2. On mesure l'erreur
//! 3. On ajuste les poids
//! 4. On recommence avec l'exemple suivant
//!
//! L'erreur moyenne devrait diminuer au fil des √©poques, signe que le r√©seau apprend.
//!
//! ### Description de la m√©thode `train`
//!
//! Impl√©menter une m√©thode publique `train` sur `NeuralNetwork` qui :
//! - Prend en param√®tres :
//!   - `inputs: &[f64]` : toutes les temp√©ratures Celsius normalis√©es d'entra√Ænement
//!   - `targets: &[f64]` : les temp√©ratures Fahrenheit normalis√©es correspondantes
//!   - `epochs: usize` : combien de fois r√©p√©ter l'entra√Ænement complet
//!   - `learning_rate: f64` : la vitesse d'apprentissage
//! - Retourne `Vec<f64>` : l'erreur moyenne de chaque √©poque (pour voir la progression)
//!
//! ### Algorithme d√©taill√©
//!
//! 1. **Cr√©er un vecteur vide pour stocker les erreurs**
//!
//! 2. **Pour chaque √©poque** (0 jusqu'√† `epochs`) :
//!    
//!    a. Initialiser une variable `total_error` √† 0.0
//!    
//!    b. **Pour chaque exemple d'entra√Ænement** (parcourir `inputs` et `targets` ensemble) :
//!       - Faire la pr√©diction : appeler `forward` avec l'entr√©e
//!       - Calculer l'erreur MSE : `0.5 √ó (pr√©diction - cible)¬≤`
//!       - Ajouter cette erreur √† `total_error`
//!       - Ajuster les poids : appeler `backward` avec la cible et les activations
//!    
//!    c. Calculer l'erreur moyenne : `total_error / nombre_d_exemples`
//!    
//!    d. Stocker cette erreur moyenne dans le vecteur
//!    
//!    e. Afficher la progression toutes les 100 √©poques :
//!       ```
//!       √âpoque 0: Erreur moyenne = 0.245613
//!       √âpoque 100: Erreur moyenne = 0.004521
//!       ```
//!
//! 3. **Retourner le vecteur contenant toutes les erreurs**
//!
//! <details>
//! <summary>üí° Indice : Parcourir deux slices ensemble</summary>
//!
//! Pour parcourir `inputs` et `targets` simultan√©ment :
//! ```rust
//! for (input, target) in inputs.iter().zip(targets) {
//!     // *input et *target sont les valeurs
//! }
//! ```
//! </details>
//!
//! ## √âtape 7 : Programme principal - Le `main`
//!
//! ### Concept g√©n√©ral
//!
//! Le programme principal assemble toutes les pi√®ces :
//! 1. Pr√©pare les donn√©es
//! 2. Cr√©e le r√©seau
//! 3. L'entra√Æne
//! 4. Teste les r√©sultats
//!
//! ### Structure d√©taill√©e du `main`
//!
//! 1. **Cr√©er les normaliseurs** :
//!    ```rust
//!    let input_normalizer = Normalizer::new(-40.0, 40.0);
//!    let output_normalizer = Normalizer::new(-40.0, 104.0);
//!    ```
//!    Note : 104¬∞F = 40¬∞C √ó 9/5 + 32
//!
//! 2. **G√©n√©rer les donn√©es d'entra√Ænement** :
//!    - Cr√©er des temp√©ratures Celsius : -40, -35, -30, ..., 35, 40
//!    - Pour chaque temp√©rature :
//!      - Calculer la temp√©rature Fahrenheit correspondante
//!      - Normaliser les deux valeurs
//!    - S√©parer en deux vecteurs avec `.unzip()`
//!
//! 3. **Cr√©er et entra√Æner le r√©seau** :
//!    ```rust
//!    let mut network = NeuralNetwork::new(1, vec![2], 1);
//!    let errors = network.train(&normalized_inputs, &normalized_outputs, 1000, 0.1);
//!    ```
//!
//! 4. **Tester le r√©seau** :
//!    - Cr√©er un tableau de temp√©ratures de test (incluant des valeurs non vues)
//!    - Pour chaque temp√©rature de test :
//!      - Normaliser avec `input_normalizer`
//!      - Pr√©dire avec `network.infer()`
//!      - D√©normaliser avec `output_normalizer`
//!      - Calculer l'erreur absolue
//!      - Afficher dans un tableau format√©
//!
//! <details>
//! <summary>üí° Indice : G√©n√©ration √©l√©gante des donn√©es</summary>
//!
//! Utiliser un it√©rateur avec `.step_by()` et `.map()` :
//! ```rust
//! (-40..=40).step_by(5).map(|c| {
//!     let celsius = c as f64;
//!     // Calculer fahrenheit
//!     // Normaliser les deux
//!     // Retourner un tuple
//! })
//! ```
//! </details>
//!
//! <details>
//! <summary>üí° Indice : Test sur plusieurs valeurs</summary>
//!
//! ```rust
//! let test_temperatures = [-50.0, -25.0, 0.0, 15.0, 37.0, 100.0];
//! for temp in test_temperatures {
//!     // Normaliser, pr√©dire, d√©normaliser
//!     // Comparer avec la vraie valeur
//! }
//! ```
//! </details>
//!
//! ## R√©sultats attendus
//!
//! Si tout est correctement impl√©ment√© :
//! - L'erreur d'entra√Ænement devrait passer de ~0.5 √† moins de 0.001
//! - Les pr√©dictions dans la plage [-40, 40] devraient avoir moins de 1¬∞F d'erreur
//! - Les pr√©dictions l√©g√®rement hors plage [-50, 50] devraient rester coh√©rentes
//! - Les pr√©dictions tr√®s hors plage (100¬∞C) peuvent √™tre impr√©cises (extrapolation difficile)

pub mod p_neuralnetwork;
